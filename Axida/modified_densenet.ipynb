{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MU1u_7yvH0aO",
    "outputId": "796a320c-3901-4726-a355-882fd2546a35"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/My\\ Drive/'Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WMaxxCSSH1mL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jhh3q7NUH8tk"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('iot23_combined_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A_IGgJwHIBQ0"
   },
   "outputs": [],
   "source": [
    "X = df[['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']]\n",
    "Y = pd.get_dummies(df['label']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TwVCNXo1IEW7"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "normalized_x = scaler.transform(X)\n",
    "scaler.fit(Y)\n",
    "normalized_y = scaler.transform(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_x, normalized_y, random_state=10, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQHmllyPEjNK",
    "outputId": "65c6f57e-c170-4312-ef72-5368ce1968b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/r5z2hy617kggbq8qw5b3k6mh0000gn/T/ipykernel_62045/2390584065.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.3939 Val Loss=1.3859 Val Acc=0.2515\n",
      "Epoch 2: Train Loss=1.3712 Val Loss=1.3852 Val Acc=0.2487\n",
      "Epoch 3: Train Loss=1.3472 Val Loss=1.3844 Val Acc=0.2487\n",
      "Epoch 4: Train Loss=1.3235 Val Loss=1.3836 Val Acc=0.2487\n",
      "Epoch 5: Train Loss=1.3004 Val Loss=1.3825 Val Acc=0.2487\n",
      "Epoch 6: Train Loss=1.2799 Val Loss=1.3812 Val Acc=0.2487\n",
      "Epoch 7: Train Loss=1.2623 Val Loss=1.3798 Val Acc=0.4508\n",
      "Epoch 8: Train Loss=1.2475 Val Loss=1.3783 Val Acc=0.5055\n",
      "Epoch 9: Train Loss=1.2356 Val Loss=1.3766 Val Acc=0.5055\n",
      "Epoch 10: Train Loss=1.2263 Val Loss=1.3747 Val Acc=0.5055\n",
      "Epoch 11: Train Loss=1.2190 Val Loss=1.3725 Val Acc=0.5055\n",
      "Epoch 12: Train Loss=1.2134 Val Loss=1.3699 Val Acc=0.5055\n",
      "Epoch 13: Train Loss=1.2089 Val Loss=1.3669 Val Acc=0.5055\n",
      "Epoch 14: Train Loss=1.2055 Val Loss=1.3636 Val Acc=0.5055\n",
      "Epoch 15: Train Loss=1.2026 Val Loss=1.3598 Val Acc=0.5056\n",
      "Epoch 16: Train Loss=1.2002 Val Loss=1.3556 Val Acc=0.5056\n",
      "Epoch 17: Train Loss=1.1983 Val Loss=1.3511 Val Acc=0.5056\n",
      "Epoch 18: Train Loss=1.1966 Val Loss=1.3461 Val Acc=0.5056\n",
      "Epoch 19: Train Loss=1.1951 Val Loss=1.3408 Val Acc=0.5056\n",
      "Epoch 20: Train Loss=1.1939 Val Loss=1.3349 Val Acc=0.5055\n",
      "Epoch 21: Train Loss=1.1928 Val Loss=1.3283 Val Acc=0.5055\n",
      "Epoch 22: Train Loss=1.1918 Val Loss=1.3213 Val Acc=0.5055\n",
      "Epoch 23: Train Loss=1.1909 Val Loss=1.3141 Val Acc=0.5055\n",
      "Epoch 24: Train Loss=1.1901 Val Loss=1.3066 Val Acc=0.5055\n",
      "Epoch 25: Train Loss=1.1895 Val Loss=1.2988 Val Acc=0.5080\n",
      "Epoch 26: Train Loss=1.1888 Val Loss=1.2909 Val Acc=0.5080\n",
      "Epoch 27: Train Loss=1.1882 Val Loss=1.2831 Val Acc=0.5080\n",
      "Epoch 28: Train Loss=1.1877 Val Loss=1.2754 Val Acc=0.5080\n",
      "Epoch 29: Train Loss=1.1873 Val Loss=1.2678 Val Acc=0.5080\n",
      "Epoch 30: Train Loss=1.1868 Val Loss=1.2604 Val Acc=0.5080\n",
      "Epoch 31: Train Loss=1.1863 Val Loss=1.2534 Val Acc=0.5080\n",
      "Epoch 32: Train Loss=1.1860 Val Loss=1.2466 Val Acc=0.5080\n",
      "Epoch 33: Train Loss=1.1857 Val Loss=1.2404 Val Acc=0.5080\n",
      "Epoch 34: Train Loss=1.1853 Val Loss=1.2347 Val Acc=0.5080\n",
      "Epoch 35: Train Loss=1.1850 Val Loss=1.2294 Val Acc=0.5080\n",
      "Epoch 36: Train Loss=1.1846 Val Loss=1.2245 Val Acc=0.5080\n",
      "Epoch 37: Train Loss=1.1844 Val Loss=1.2200 Val Acc=0.5080\n",
      "Epoch 38: Train Loss=1.1842 Val Loss=1.2159 Val Acc=0.5080\n",
      "Epoch 39: Train Loss=1.1840 Val Loss=1.2121 Val Acc=0.5080\n",
      "Epoch 40: Train Loss=1.1837 Val Loss=1.2088 Val Acc=0.5087\n",
      "Epoch 41: Train Loss=1.1836 Val Loss=1.2057 Val Acc=0.5087\n",
      "Epoch 42: Train Loss=1.1834 Val Loss=1.2029 Val Acc=0.5087\n",
      "Epoch 43: Train Loss=1.1832 Val Loss=1.2005 Val Acc=0.5088\n",
      "Epoch 44: Train Loss=1.1830 Val Loss=1.1983 Val Acc=0.5116\n",
      "Epoch 45: Train Loss=1.1828 Val Loss=1.1963 Val Acc=0.5116\n",
      "Epoch 46: Train Loss=1.1827 Val Loss=1.1946 Val Acc=0.5116\n",
      "Epoch 47: Train Loss=1.1826 Val Loss=1.1930 Val Acc=0.5116\n",
      "Epoch 48: Train Loss=1.1823 Val Loss=1.1917 Val Acc=0.5117\n",
      "Epoch 49: Train Loss=1.1823 Val Loss=1.1905 Val Acc=0.5118\n",
      "Epoch 50: Train Loss=1.1821 Val Loss=1.1894 Val Acc=0.5118\n",
      "Epoch 51: Train Loss=1.1820 Val Loss=1.1884 Val Acc=0.5118\n",
      "Epoch 52: Train Loss=1.1818 Val Loss=1.1875 Val Acc=0.5118\n",
      "Epoch 53: Train Loss=1.1817 Val Loss=1.1868 Val Acc=0.5118\n",
      "Epoch 54: Train Loss=1.1816 Val Loss=1.1861 Val Acc=0.5118\n",
      "Epoch 55: Train Loss=1.1815 Val Loss=1.1854 Val Acc=0.5118\n",
      "Epoch 56: Train Loss=1.1814 Val Loss=1.1849 Val Acc=0.5118\n",
      "Epoch 57: Train Loss=1.1813 Val Loss=1.1844 Val Acc=0.5118\n",
      "Epoch 58: Train Loss=1.1812 Val Loss=1.1839 Val Acc=0.5118\n",
      "Epoch 59: Train Loss=1.1811 Val Loss=1.1836 Val Acc=0.5118\n",
      "Epoch 60: Train Loss=1.1809 Val Loss=1.1832 Val Acc=0.5118\n",
      "Epoch 61: Train Loss=1.1809 Val Loss=1.1829 Val Acc=0.5118\n",
      "Epoch 62: Train Loss=1.1809 Val Loss=1.1826 Val Acc=0.5177\n",
      "Epoch 63: Train Loss=1.1807 Val Loss=1.1824 Val Acc=0.5092\n",
      "Epoch 64: Train Loss=1.1807 Val Loss=1.1821 Val Acc=0.5092\n",
      "Epoch 65: Train Loss=1.1806 Val Loss=1.1819 Val Acc=0.5092\n",
      "Epoch 66: Train Loss=1.1805 Val Loss=1.1817 Val Acc=0.5092\n",
      "Epoch 67: Train Loss=1.1804 Val Loss=1.1816 Val Acc=0.5092\n",
      "Epoch 68: Train Loss=1.1803 Val Loss=1.1814 Val Acc=0.5092\n",
      "Epoch 69: Train Loss=1.1801 Val Loss=1.1812 Val Acc=0.5092\n",
      "Epoch 70: Train Loss=1.1801 Val Loss=1.1811 Val Acc=0.5092\n",
      "Epoch 71: Train Loss=1.1801 Val Loss=1.1810 Val Acc=0.5092\n",
      "Epoch 72: Train Loss=1.1800 Val Loss=1.1809 Val Acc=0.5092\n",
      "Epoch 73: Train Loss=1.1799 Val Loss=1.1807 Val Acc=0.5092\n",
      "Epoch 74: Train Loss=1.1799 Val Loss=1.1806 Val Acc=0.5092\n",
      "Epoch 75: Train Loss=1.1798 Val Loss=1.1805 Val Acc=0.5092\n",
      "Epoch 76: Train Loss=1.1797 Val Loss=1.1804 Val Acc=0.5092\n",
      "Epoch 77: Train Loss=1.1797 Val Loss=1.1803 Val Acc=0.5092\n",
      "Epoch 78: Train Loss=1.1796 Val Loss=1.1803 Val Acc=0.5092\n",
      "Epoch 79: Train Loss=1.1796 Val Loss=1.1802 Val Acc=0.5092\n",
      "Epoch 80: Train Loss=1.1795 Val Loss=1.1801 Val Acc=0.5092\n",
      "Epoch 81: Train Loss=1.1794 Val Loss=1.1800 Val Acc=0.5092\n",
      "Epoch 82: Train Loss=1.1793 Val Loss=1.1800 Val Acc=0.5092\n",
      "Epoch 83: Train Loss=1.1793 Val Loss=1.1799 Val Acc=0.5092\n",
      "Epoch 84: Train Loss=1.1793 Val Loss=1.1798 Val Acc=0.5092\n",
      "Epoch 85: Train Loss=1.1793 Val Loss=1.1798 Val Acc=0.5092\n",
      "Epoch 86: Train Loss=1.1792 Val Loss=1.1797 Val Acc=0.5092\n",
      "Epoch 87: Train Loss=1.1791 Val Loss=1.1796 Val Acc=0.5092\n",
      "Epoch 88: Train Loss=1.1791 Val Loss=1.1796 Val Acc=0.5092\n",
      "Epoch 89: Train Loss=1.1790 Val Loss=1.1795 Val Acc=0.5092\n",
      "Epoch 90: Train Loss=1.1788 Val Loss=1.1795 Val Acc=0.5092\n",
      "Epoch 91: Train Loss=1.1788 Val Loss=1.1794 Val Acc=0.5092\n",
      "Epoch 92: Train Loss=1.1788 Val Loss=1.1794 Val Acc=0.5092\n",
      "Epoch 93: Train Loss=1.1787 Val Loss=1.1793 Val Acc=0.5092\n",
      "Epoch 94: Train Loss=1.1787 Val Loss=1.1793 Val Acc=0.5092\n",
      "Epoch 95: Train Loss=1.1787 Val Loss=1.1792 Val Acc=0.5092\n",
      "Epoch 96: Train Loss=1.1787 Val Loss=1.1792 Val Acc=0.5092\n",
      "Epoch 97: Train Loss=1.1786 Val Loss=1.1792 Val Acc=0.5092\n",
      "Epoch 98: Train Loss=1.1785 Val Loss=1.1791 Val Acc=0.5092\n",
      "Epoch 99: Train Loss=1.1785 Val Loss=1.1791 Val Acc=0.5092\n",
      "Epoch 100: Train Loss=1.1785 Val Loss=1.1790 Val Acc=0.5092\n"
     ]
    }
   ],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        out = self.fc4(out)\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_val = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = DenseNet(num_classes=4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = nn.CrossEntropyLoss()(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val)\n",
    "        _, normal_y_val = torch.max(y_val.data,1)\n",
    "        val_loss = nn.CrossEntropyLoss()(y_pred, y_val)\n",
    "        val_acc = (y_pred.argmax(1) == normal_y_val).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={loss.item():.4f} Val Loss={val_loss.item():.4f} Val Acc={val_acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'densenet.pt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
